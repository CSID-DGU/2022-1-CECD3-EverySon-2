
emotion:
  _target_: src.models.CoMPM_module.CoMPM.load_from_checkpoint
  checkpoint_path: checkpoint/model.ckpt

tokenizer:
  _target_: transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: klue/roberta-base

gpt_tokenizer:
  _target_: transformers.AutoTokenizer.from_pretrained
  pretrained_model_name_or_path: kakaobrain/kogpt
  revision: KoGPT6B-ryan1.5b-float16
  bos_token: "[BOS]"
  eos_token: "[EOS]"
  unk_token: "[UNK]"
  pad_token: "[PAD]"
  mask_token: "[MASK]"

gpt:
  _target_: transformers.AutoModelForCausalLM.from_pretrained
  pretrained_model_name_or_path: kakaobrain/kogpt
  revision: KoGPT6B-ryan1.5b-float16
  torch_dtype: auto
  low_cpu_mem_usage: True
